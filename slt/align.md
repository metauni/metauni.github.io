---
title:
    metauni Alignment Project
description:
    There are no algebraists in foxholes
---

In physics, critical points refer to the specific conditions at which a system undergoes a phase transition. Many systems near a critical point exhibit a property called scale invariance, and their mathematical description falls into specific categories known as universality classes which group together systems that display similar characteristics. Here we sketch an approach to scalable mechanistic interpretability of neural networks based on the following hypothesis:

* **Universality hypothesis**: some of the representations and algorithms encoded by neural networks are approximately universal.

If this hypothesis holds for a sufficiently broad class of the computations carried out by a network, then interpretability could be an effective foundation for aligning advanced AI systems.


Conformal field theory (CFT) plays a crucial role in understanding and describing the behavior of systems near critical points. CFT is a powerful mathematical framework that provides a way to understand the behavior of quantum field theories in two dimensions. By characterizing the critical behavior of a system within a specific universality class using CFT, physicists can make predictions about the system's behavior at critical points and beyond. This has significant implications for a wide range of fields, including condensed matter physics, statistical mechanics, and high-energy physics.

Physical systems near critical points often exhibit scale invariance, and a
Some physical systems near critical points exhibit scale invariance, and as a result their behaviour is well-approximated by a 

The following is a plan for scaling mechanistic interpretability of neural networks, assuming that there are scaling limits in which the behaviour is approximately universal. 

- **Hypothesis**: In scaling limits relevant to AGI, neural networks compute using representations that are approximately universal.


- The relation between learning behaviour and jet schemes,
- Renormalisation Group methods, and the LG/CFT correspondence.



All neural networks are assumed to be large, e.g. significantly larger than GPT3. We envision a large scale family of devices which have access to the training process of the model

- Libraries of questions and probes on subdistributions that have been designed to capture concepts we care about
- Checkpoints of the larger model are passed into this examination system

If aligning an AGI is possible, it **must be because of affordances due to universality**. We're talking about controlling a system at scales that range from sub-human intelligence to vastly superhuman intelligence, and the key problem is how to engineer solutions that remain effective across this wide range of scales. The shadow of this problem can be seen in the "sharp left turn". This may be possible if enough critical components of the system being aligned are *universal*.

## Neural Spectroscopy

By analogy with scanning tunneling microscopes in solid state physics (ref, ref), we assume that it is possible to construct "devices" (software) which 

## Universal means interpretable

## We can develop a theory of universality in learning machines

Notes

- In some limit, trajectories interacting with noise behave like particles in a supersymmetric field theory. Then to study transitions you want to group trajectories into kinds which involve rep theory
- systems coupled to noise see the jet scheme

## Spectroscopy at Scale

- automated discovery of band structure

## Concepts as Components

## Programs as Processes

- See more data -> simple model breaks. But how does it break?

## Universality and CFT

Suppose we have a spectroscope. Then we can look at degenercies in the DOS for the network, or for parts of weight space encountered by training. This gives us some idea of the nature of the singularities encountered and the universality class. We match this against empirically observed behaviour (e.g. performance on a battery of tests) to infer what kind of progress was made in each phase transition. We develop a kind of spectroscope that can detect components of the resolution of singularities / via jet scheme ideas.

Components are like the spectrum, if the phase transitions are gradual enough most of them won't change, and we can track the changes to particular components and match that up with the conceptual changes. This gives us a picture, over training, of the programs that are being formed.

Programs as singularities, we can test out these ideas on models of computation that we understand and build up a dictionary.

The theory in the background is via LG/CFT components of jet schemes = representations of vertex algebras, we know how that fits into universality, RG flows.

How are these programs actually executed? 

Second-order phase transitions are deformations of singularities. We have some understanding of the "symbolic content" of these deformations, from LG/CFT. It can be operationalised to build probes.
